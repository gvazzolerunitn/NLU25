# Training Configuration
Parameter	Value
model	LM_LSTM
optimizer	AdamW
learning_rate	0.0001
embedding_size	300
hidden_size	200
clip	5
dropout_embedding	Dropout(p=0.1, inplace=False)
dropout_output	Dropout(p=0.1, inplace=False)
patience	3
epochs_ran	99
best_ppl	138.44982292838313

# Training Results Per Epoch
Epoch	Training Loss	Validation Loss	Validation Perplexity
1	7.118309	6.618217	748.609
2	6.574263	6.507951	670.451
3	6.446632	6.368628	583.257
4	6.316577	6.247976	516.965
5	6.202939	6.144462	466.129
6	6.102758	6.054211	425.903
7	6.013822	5.972889	392.638
8	5.931110	5.897408	364.092
9	5.856121	5.830531	340.539
10	5.790231	5.773417	321.635
11	5.732238	5.720917	305.185
12	5.679642	5.676759	292.002
13	5.632499	5.637425	280.739
14	5.588877	5.600317	270.512
15	5.549259	5.568476	262.035
16	5.512820	5.537851	254.131
17	5.478460	5.509575	247.046
18	5.446467	5.484827	241.007
19	5.415938	5.461264	235.395
20	5.386801	5.438175	230.022
21	5.359409	5.416939	225.189
22	5.333287	5.397404	220.832
23	5.307937	5.379058	216.818
24	5.284641	5.362240	213.202
25	5.261507	5.345526	209.668
26	5.239509	5.329928	206.423
27	5.218492	5.314090	203.180
28	5.197969	5.300333	200.403
29	5.178538	5.286354	197.622
30	5.159677	5.274021	195.199
31	5.141156	5.261676	192.804
32	5.123704	5.250404	190.643
33	5.107295	5.237303	188.162
34	5.090102	5.227847	186.391
35	5.074013	5.217304	184.436
36	5.057928	5.206054	182.373
37	5.042601	5.196726	180.680
38	5.027322	5.187421	179.006
39	5.012709	5.177333	177.210
40	4.998903	5.169816	175.883
41	4.985003	5.161206	174.375
42	4.971576	5.152737	172.904
43	4.957791	5.145310	171.625
44	4.945329	5.137481	170.286
45	4.932637	5.130613	169.121
46	4.920439	5.123480	167.919
47	4.909214	5.116358	166.727
48	4.896023	5.109335	165.560
49	4.884487	5.103709	164.631
50	4.872873	5.096075	163.379
51	4.861501	5.091251	162.593
52	4.850785	5.083642	161.361
53	4.839368	5.078854	160.590
54	4.829417	5.073588	159.746
55	4.819174	5.067277	158.741
56	4.808549	5.062413	157.971
57	4.797705	5.056854	157.095
58	4.788046	5.051526	156.261
59	4.777937	5.047259	155.595
60	4.768894	5.042521	154.860
61	4.758831	5.037026	154.011
62	4.749474	5.033742	153.506
63	4.740599	5.030156	152.957
64	4.731479	5.025510	152.248
65	4.722855	5.020707	151.518
66	4.714427	5.017547	151.040
67	4.705020	5.011811	150.176
68	4.696892	5.008876	149.736
69	4.687891	5.006105	149.322
70	4.679710	5.002149	148.732
71	4.671168	4.999055	148.273
72	4.663782	4.994543	147.606
73	4.654584	4.991461	147.151
74	4.647029	4.989943	146.928
75	4.640339	4.986910	146.483
76	4.632260	4.983625	146.003
77	4.624955	4.979493	145.401
78	4.616350	4.975855	144.873
79	4.610141	4.973418	144.520
80	4.601940	4.971672	144.268
81	4.595479	4.969175	143.908
82	4.587328	4.964909	143.296
83	4.579686	4.963414	143.081
84	4.572215	4.960740	142.699
85	4.567132	4.958931	142.441
86	4.559727	4.955729	141.986
87	4.552845	4.952858	141.579
88	4.546230	4.950416	141.234
89	4.539329	4.949787	141.145
90	4.531992	4.946724	140.713
91	4.525737	4.943711	140.290
92	4.519767	4.942181	140.075
93	4.513368	4.939665	139.724
94	4.507454	4.938090	139.504
95	4.500121	4.936643	139.302
96	4.494035	4.933898	138.920
97	4.487011	4.932249	138.691
98	4.481610	4.931971	138.652
99	4.474922	4.930508	138.450

# Final Evaluation Metrics
Final Epoch Validation Perplexity	138.450
Best Validation Perplexity	138.450
Test Perplexity	127.514
